# **Auto Grader with LLM Detector**

This application is a robust, Python-based desktop tool designed to streamline the process of assessing student submissions. At its core, it integrates two powerful capabilities: automated grading and intelligent detection of text generated by Large Language Models (LLMs). The user-friendly graphical interface, built with Tkinter, allows educators to easily upload student work and corresponding answer keys in common formats like PDF and TXT. Beyond simple scoring, the application provides a comprehensive analysis, including a confidence score for AI-generated content, linguistic metrics, and the ability to visualize and save historical data, making it a valuable asset for modern educational environments. The tool's design emphasizes data persistence and the ability to improve its core functionality over time through user-provided training data.

## **Key Features**

### **Automated Test Grading**

The automated grading feature is built upon a sophisticated text comparison algorithm that leverages **TF-IDF (Term Frequency-Inverse Document Frequency)** and **cosine similarity**. This process begins by transforming the student's submission and the official answer key into a numerical representation that captures the importance of each word within the documents. Unlike a simple keyword match, TF-IDF weights terms based on their relevance, ensuring that the analysis focuses on the most significant concepts. The application then calculates the cosine similarity, which measures the angle between these two document vectors. A smaller angle indicates greater similarity, resulting in a higher grade score. The final result is presented as a clear percentage, providing a quantitative and objective measure of how well the student's work aligns with the expected answer.

### **Large Language Model (LLM) Detection**

A central and highly innovative feature of this application is its ability to identify content potentially written by an LLM. This is achieved through a machine learning model, specifically a **Logistic Regression classifier**, which has been trained to distinguish between human-written and AI-generated text. The model analyzes various linguistic features, such as perplexity, burstiness, and a general lack of variation in sentence structure and word choice, which are often characteristic of AI-generated prose. After processing a student's submission, the model outputs a confidence score, ranging from 0% (highly likely human-written) to 100% (highly likely AI-generated), providing a crucial data point for educators concerned about academic integrity. This detection capability is dynamic and can be continuously improved by retraining the model with new data.

### **Data Persistence and Management**

To ensure that all valuable analysis results are not lost, the application utilizes a local **SQLite database** for data persistence. This database serves as a centralized repository for every analysis performed, storing key metrics like the grade score, LLM confidence, readability score, and word count. Each analysis is logged with a specific class name and a timestamp, allowing educators to track the performance of an entire class over time. This structured data storage is not only for historical record-keeping but also serves as the foundation for the application's powerful visualization features. Furthermore, this data management system enables users to easily add new training examples to the database, which is crucial for improving the accuracy and performance of the LLM detection model.

### **Data Visualization and Reporting**

The application provides robust tools for visualizing and reporting on the collected data. The user can generate various types of graphs, powered by the matplotlib library, to gain deeper insights into class performance and writing trends. These visualizations include line graphs showing grade scores or LLM confidence over time, as well as scatter plots that can reveal correlations between different metrics, such as a student's grade versus the LLM confidence score. In addition to the visual component, a comprehensive analysis report is generated for each submission. This report, displayed in the application's text box, summarizes all findings and can be easily exported as a clean and professional **TXT or PDF document** for archiving or sharing with students and administrators.

## **How It Works**

### **Initial Setup and Model Training**

The first time the application is launched, it performs a crucial check for the LLM detection model. If the model is not found, it intelligently prompts the user to provide initial training data. This is a critical step, as the model's accuracy is directly dependent on the quality and quantity of its training set. The application offers two flexible methods for this: the user can either select a CSV file containing text and label columns (where 0 represents human and 1 represents AI), or simply point to a folder containing text files that are appropriately labeled in their filenames (e.g., essay\_human.txt or report\_llm.pdf). This process saves the data to the SQLite database and trains the Logistic Regression model, after which the application is ready for use.

### **The Analysis Pipeline**

Once a student submission and an answer key have been uploaded, the application initiates a multi-stage analysis pipeline. First, it uses the **PyMuPDF (fitz)** library to extract raw text from the uploaded PDF or TXT files. This extracted text is then preprocessed to clean and prepare it for analysis. The pipeline then branches into two parallel paths: the grading path and the LLM detection path. For grading, the preprocessed texts are vectorized using TF-IDF and compared using cosine similarity. For LLM detection, the student's text is analyzed for linguistic features and fed into the trained Logistic Regression model. This parallel processing ensures that both analyses are completed efficiently, providing the user with a comprehensive report in a timely manner.

### **Output Generation and Data Logging**

Upon completion of the analysis, the application generates a comprehensive report that is displayed directly within the GUI. This report provides a clear breakdown of the grade score, the LLM confidence score, and other valuable linguistic metrics like word count and a simple readability score. At the same time, all of these data points, along with the class name and the date of the analysis, are logged to the local SQLite database. This seamless integration of reporting and data logging ensures that every analysis contributes to the long-term dataset, which can then be used for future trend analysis and for retraining the model with an ever-growing corpus of real-world examples.

## **Getting Started**

### **Installation and Dependencies**

To get started with the application, you must first ensure that all necessary Python libraries are installed. The core dependencies include PyMuPDF for handling PDF files, scikit-learn and numpy for the machine learning components, matplotlib for graphing, spacy for advanced text preprocessing, and pandas for data handling. While some of these may already be on your system, it is recommended to install them all to avoid conflicts. You can use the following commands in your terminal to install the required packages and the English language model for spaCy:  
pip install PyMuPDF scikit-learn numpy matplotlib spacy reportlab pandas  
python \-m spacy download en\_core\_web\_sm

You can also use the “requrement.txt” file that came downloaded with the program just do the following:  
1\.  Install the python version that matches your computer’s operating system (OS) from:  
 [https://www.python.org/downloads/](https://www.python.org/downloads/)  
2\. Run this command in terminal:  
python \-m venv venv  
    source venv/bin/activate  
3\. Run this in terminal:    
pip install \-r path/to/requirements.txt  
Or   
pip3 install \-r path/to/requirements.txt  
Replace “path/to/ ”with the actual directory path to the downloaded requirements.txt file.  
4\. Run the following commands in terminal depending on your python version that you have installed:   
python \-m spacy download en\_core\_web\_sm  
Or   
python3 \-m spacy download en\_core\_web\_sm  
5\. Run this in terminal:  
Python path/to/auto grader.py  
Or   
Python3 path/to/auto grader.py  
Replace “path/to/” with the actual directory path to the downloaded auto grader.py file.  
 

 

### **User Guide**

Using the application is a straightforward process. First, launch the application by running the auto\_grader.py script from your terminal. If it's your first time, follow the on-screen prompts to set up the LLM detection model. In the main window, you will find several key controls. Begin by entering a **Class Name** to categorize your analysis data. Next, use the two "Upload PDF" buttons to select the student's test and the corresponding answer key from your computer. Once both files are selected, click the **"Analyze & Grade"** button. The application will process the files and display a full report in the text box below. You can then use the **"Generate Graph"** button to visualize your data, and the **"Save Report"** button to save the analysis as a separate file. Finally, if you acquire more training data, you can use the **"Add Training Data"** button to retrain the model and enhance its accuracy.
