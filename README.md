# **Auto Grader** 

## **Overview and Purpose**

The **Auto Grader** is a robust, Python-based desktop application specifically designed to transform the often time-consuming and manual process of assessment for instructors, teachers, and teaching assistants. Built upon the reliable and native-feeling **Tkinter GUI framework**, its core functionality centers on automating two critical academic tasks: **efficiently scoring student assignments** and providing an initial, data-driven layer of **detection for content potentially generated by large language models (LLMs)**.

This tool functions as a groundbreaking **hybrid assessment system**. It allows for both **fast, objective scoring**—perfect for checking factual comprehension and compliance—via **keyword-based grading**, and a more comprehensive, **AI-driven qualitative analysis** designed to evaluate nuanced metrics like writing quality, coherence, and argumentative structure using a local language model. The overarching goal is strategically twofold: first, to drastically **reduce the time spent on repetitive scoring** and clerical tasks, freeing educators to focus more on personalized student interaction and curriculum innovation; and second, to actively support **academic integrity** in the digital age by providing immediate, quantitative insights into the origin of submitted work. This application brings cutting-edge, yet accessible, machine learning tools directly to the educator's desktop environment.

## **Setup and Installation**

To successfully deploy and run the Auto Grader, you'll need a stable Python environment. We strongly recommend **Python version 3.8 or higher** to ensure robust compatibility with all modern machine learning libraries, especially PyTorch and the HuggingFace Transformers, which rely on recent Python features for optimal performance and security updates.

### **Step 1: Install Dependencies**

All necessary software packages—which form the complete technical stack for this hybrid system—are carefully listed in the accompanying requirements.txt file. You can install this entire set of dependencies quickly and efficiently using the Python package installer, pip, directly from your terminal or command prompt:

pip install \-r requirements.txt

This single command installs the full suite of tools:

* **GUI and Input/Output Tools:** **PyPDF2** for robust document parsing and text extraction, and **reportlab** for generating high-quality, professional PDF reports suitable for distribution or archiving.  
* **Data Processing:** **nltk** (Natural Language Toolkit) is fundamental. It handles low-level linguistic tasks like **tokenization** (breaking text into words and sentences) and linguistic analysis, which is necessary before any machine learning model can operate effectively.  
* **Machine Learning Stack:** **scikit-learn** provides the foundation for classic machine learning algorithms, notably the Logistic Regression Classifier used for detection. **joblib** handles the fast saving and loading of the trained models and their associated vectorizers so you only need to complete the intensive training process once.  
* **Deep Learning Components:** **transformers** and **torch** are crucial for running the small, efficient language model used in the AI-Assisted Grading feature, ensuring complex, generative analysis can run quickly and securely on your local machine.  
* **Visualization and Data Sources:** **matplotlib** creates the graphical summaries of grading data, and the **datasets** library allows the application to easily pull large, public training datasets required for training the LLM detection model.

### **Step 2: Run the Application**

Once the dependency installation completes without errors, you can launch the application by executing the main Python file from your terminal:

python "auto grader.py"

Please note that upon the very first launch, the application will use the nltk library to download essential linguistic data, specifically the **punkt tokenizer data**. This is a standard, automated, one-time process necessary for accurate text segmentation and parsing before any grading or detection can occur. You will see a brief console message during this initial download, after which the application interface will load.

## **How to Use the Application: A Step-by-Step Workflow**

The Auto Grader is designed for a clear, sequential user experience within its single-window desktop interface.

1. **Input Text:** The crucial first step is loading the student's work. You have two flexible options:  
   * **Direct Paste:** Immediately paste the essay, code snippet (for detection), or short-answer text into the large, **scrollable text box**. This is ideal for quick checks.  
   * **PDF Upload:** Use the **Upload Assignment PDF** button. The application will process the file and load all extracted text into the box automatically.  
2. **Select Action:** With the content loaded, you choose your primary function via the clearly labeled buttons:  
   * **Grade the assignment:** Proceed to step 3 after selecting either the keyword-based or AI-assisted method.  
   * **Train the AI detection model:** **Crucial for first-time use**. This initiates a background process to create the persistent detection models.  
   * **Detect AI text:** Run the loaded assignment through the trained model to check for machine-generated content.  
3. **Grading Configuration:** If you choose to grade, use the radio buttons to select your method and provide the required input:  
   * For **Keyword-based**, input the scoring key (e.g., mitosis:5, cell wall:5).  
   * For **AI-Assisted**, you’ll enter the comprehensive grading rubric or instructions for the AI model to follow (e.g., "Score the flow, clarity, and evidence on a scale of 1-10. Suggest one structural improvement.").  
4. **Review and Export:** After the system finishes processing, a detailed result pop-up appears. Here, you can immediately review the final score, the AI detection confidence level, and any qualitative feedback generated. Crucially, this step also offers the ability to **download the detailed grading report** in TXT or PDF format and view the accompanying **visualization graph** created by Matplotlib.

## **Feature Deep Dive: Assignment Upload and Input**

The application's utility is rooted in its ability to process diverse submission formats accurately.

* **Direct Text Input:** This is the quickest path for short-form assessments or for testing the detection feature on copied text from online sources or code comments. Its immediacy makes it an invaluable feature for peer review comments or small factual quizzes.  
* **PDF Upload:** The application uses the **PyPDF2 library** specifically because it offers a reliable, low-level method for text extraction. This feature is particularly robust, handling multi-page documents, different font encodings, and complex text layouts by systematically reading the content from every page in sequence. This process ensures **high text fidelity**—meaning the analysis window receives an accurate, continuous stream of the student's submission—saving the user the manual, often error-prone task of copying text from long student essays or reports.

## **Feature Deep Dive: Keyword-based Grading**

This method is designed for speed, objective clarity, and consistent application across large batches of technical or vocabulary-heavy assignments.

* **Mechanism:** The user provides a grading key using a simple syntax, such as photosynthesis:10, chlorophyll:5, light spectrum:5. The system first performs **tokenization** on the student's text, breaking it down into individual words and phrases, and then performs a strict presence check against the defined keywords. This method is ideal for questions where the goal is to verify the inclusion of specific technical facts, vocabulary, or component names required by the prompt.  
* **Scoring and Output:** A point is awarded solely for the **unbiased presence** of the required keyword. For example, in a history quiz, the system can instantly verify if terms like "Treaty of Versailles" or "Great Depression" were mentioned. The final result displays the total accumulated score alongside a clear, itemized list indicating which keywords were successfully matched and which were missed. This instantaneous, objective feedback is perfect for managing large classes where consistency is paramount. Its key limitation is its scope: it only verifies *what* is written, not the quality or context of *how* it is used.

## **Feature Deep Dive: AI-Assisted Grading (LLM)**

When an assessment requires qualitative feedback on complex elements like argument coherence, writing style, or conceptual depth, the local LLM is engaged.

* **Model Used:** The application runs a highly efficient small transformer model, **Qwen2.5-0.5B-Instruct**, accessed through the HuggingFace transformers library and powered by **PyTorch (torch)**. The decision to use a *small, locally-run model* is intentional and critical. It guarantees **faster inference speed** (results are near-instantaneous), drastically **reduces reliance on external internet access**, and, most importantly, provides a superior layer of **student data privacy** because the sensitive assignment text never leaves the user's computer to be processed by an external cloud API.  
* **Mechanism:** The user supplies a detailed **grading rubric or instruction set** (e.g., "Assess the essay for a clear thesis, support evidence from primary sources, and overall argumentative flow. Score out of 50 and give suggested structural changes."). The model processes this rubric as a guiding prompt and the student text as the primary content, generating human-like qualitative feedback. This feature is superb for evaluating essays, short stories, or conceptual explanations where subjective elements like tone and flow are important, offering feedback that goes beyond just a score.

## **Feature Deep Dive: AI Text Detection**

This is a vital, preventative tool to support academic honesty by providing quantitative guidance on the text's origin.

* **Training:** This is the most crucial setup step for detection. By pressing the **Train LLM Text Detection Model** button, the system loads diverse, publicly available training datasets via the HuggingFace datasets library. It then trains a custom **Logistic Regression Classifier** using **TF-IDF Vectorization**. **TF-IDF** (Term Frequency-Inverse Document Frequency) is a method that converts text into numerical weights, measuring how important a word is to a document. **Logistic Regression** then uses these weights to draw a decision boundary, effectively learning the subtle differences in word choice and syntactic patterns between human-written and machine-generated content. The resulting models (.joblib files) are saved locally, meaning the intensive training process only occurs once.  
* **Detection:** When the trained model analyzes new text, it outputs a clear label (**"AI-Generated"** or **"Human-Written"**) and a **confidence score** (e.g., 95.2%). This score is vital—a submission flagged at 98% confidence is treated differently than one at 55%. The application explicitly includes a warning in the results: **"AI detection is not foolproof and can make mistakes."** The result is designed to serve as a **guidance tool**, alerting the instructor to submissions that warrant a closer human review, rather than being used as absolute proof of misconduct. This helps efficiently triage a large volume of papers.

## **Feature Deep Dive: Reporting and Visualization**

Clear, archival output is essential for detailed record-keeping, self-reflection, and data analysis of class performance.

* **Visualization:** After a grading session, the system uses **Matplotlib** to instantly generate graphical feedback. These visualizations are highly informative, offering metrics such as:  
  * **Score Distribution:** A histogram showing how scores are spread across the entire class (e.g., how many students fall into A, B, C categories).  
  * **Efficiency Gains:** A simple chart comparing the estimated human grading time versus the automated system's processing time.  
  * This offers instructors a fast, visual method for checking overall class comprehension and justifying the efficiency gains of using the application.  
* **Detailed Reports:** The ability to generate persistent, professional reports is a core strength. The application creates reports in two key formats for maximum flexibility:  
  * **Plain Text (.txt):** A simple, machine-readable summary (including scores and brief feedback) useful for quickly copying data into external learning management systems (LMS) or spreadsheets.  
  * **PDF Document (.pdf):** Using the **ReportLab** library, a clean, professionally formatted PDF report is generated. This report is comprehensive, including essential metadata (date, time, method used), the student's original input text, the final numerical score, the AI detection result and confidence (if run), and all qualitative feedback from the AI-Assisted Grading. This makes it perfect for official archiving or for providing formal, printable feedback directly to the student.

## **Potential Applications in the Real World**

The flexibility of the Auto Grader makes it a valuable asset across several sectors beyond traditional classrooms:

* **K-12 and Higher Education:** This is the primary use case. Instructors can use **Keyword-based Grading** to rapidly score short-answer quizzes in STEM subjects (e.g., biology, engineering facts). They can use the **AI-Assisted mode** for structural feedback on essay drafts, helping students improve before final submission. It's also critical for flagging lab reports that exhibit unusual writing patterns, prompting a closer look to ensure genuine understanding. The substantial time saved grading dozens of assignments frees up valuable time for direct student engagement.  
* **Corporate Training and Onboarding:** Companies can utilize **Keyword-based Grading** to automatically score required internal knowledge checks on complex material, instantly certifying employee comprehension of new policies, safety procedures, or technical facts. For instance, a compliance module could verify the presence and correct usage of key legal terms, standardizing verification across large, global teams and significantly reducing the HR or training department's manual review workload.  
* **Content Moderation and Quality Control:** Beyond academic integrity, the **AI detection feature** can be adapted for large online platforms. By running user-submitted text (like comments, forum posts, or product reviews) through the model, platforms can identify and flag potentially low-quality, repetitive, or bot-generated content. This helps maintain higher editorial standards and ensures genuine community engagement.  
* **Internal Peer Review and Editing:** The **AI-Assisted Grading feature**, paired with specific, targeted internal rubrics (e.g., "Check for clarity and adherence to the client's style guide, rating on a scale of 1-5"), can be used to quickly standardize the quality of feedback across a team of technical writers or editors. This ensures consistency when multiple employees are evaluating internal documents, such as technical manuals or marketing copy, providing objective critiques aligned with company standards.

## **Credits and Dependencies**

The Auto Grader is built upon the collective strength of the open-source community. The selection of these specific libraries prioritizes local performance, speed, and data privacy.

### **Core Libraries**

* **GUI and I/O:** **tkinter** provides the reliable, cross-platform desktop interface. **PyPDF2** enables the crucial PDF input functionality.  
* **Reporting:** **reportlab** is selected for its stability in generating professional, multi-page PDF output reports.  
* **Visualization:** **matplotlib** is the standard for static plotting in Python, used here to create clear, analytical graphs of grading data.

### **Machine Learning and NLP Stack**

* **Data Processing:** **nltk** is essential for all text preprocessing tasks, ensuring clean data goes into the models.  
* **Model Training and Persistence:** **scikit-learn** is chosen for its efficient and proven implementation of classic machine learning algorithms. **joblib** is used specifically because it is fast and lightweight for saving and loading Python objects like the trained models.  
* **Deep Learning Frameworks:** **torch** (PyTorch) and **transformers** (HuggingFace) provide the necessary infrastructure to run complex, pre-trained models locally.  
* **Data Sources:** **datasets** makes the process of loading large, public datasets for the one-time model training effortless.

### **External Models**

* **Qwen2.5-0.5B-Instruct:** This is the specific, small, and highly efficient transformer model used for providing **qualitative feedback** during AI-Assisted Grading. It is chosen for its balance of high instruction-following capability and low computational overhead for local use.  
* **Logistic Regression Classifier:** This is the custom-trained machine learning model, built with scikit-learn, dedicated solely to providing a quantitative **LLM text detection** probability score.
